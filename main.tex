\documentclass[conference]{IEEEtran}


%XXX Remove before final submission
\usepackage{todonotes}
\usepackage{cite}
\usepackage{amsmath}
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
\usepackage{url}

% correct bad hyphenation here
\hyphenation{}


\begin{document}

%XXX remove before submission
\newcommand{\TODO}[1]{\todo[inline]{#1}}
\newcommand{\TODOFIG}[1]{\missingfigure{#1}}

\title{The Statistics of Benchmarks for Testing Perfomance Regressions}

% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{\IEEEauthorblockN{Jiahao Chen and Jarrett Revels}
\IEEEauthorblockA{Computer Science and Artificial Intelligence Laboratory\\
Massachusetts Institute of Technology\\
Cambridge, Massachusetts 02139--4307\\
Email: \{jiahao,jrevels\}@csail.mit.edu}
}

% make the title area
\maketitle

\begin{abstract}
\TODO{The abstract goes here.}
\end{abstract}

\IEEEpeerreviewmaketitle

\section{Introduction}

If we want to be able to say that ``Program A is faster than Program B'', we
need to time both programs.

Modern computer systems make benchmarking hard. They do many things under the
hood that can screw up the comparison~\cite{HP5e}.

\subsection{Factors affecting timings}

\TODO{jrevels to fill in}


\subsection{Quiescence}

There is a lot of work trying to make the system more reliable, reducing variation. Some examples are \TODO{MORE} . But in practice it is still impossible to eliminate every single source of jitter. In these cases where there is irreducible jitter we have no choice but to resort to a statistical description of the benchmarking process.


\section{Methodology}

\subsection{A compromise between timer accuracy and jitter determines how many times to run the benchmark}

For benchmarks that take very little time to run, it is vital to run it many times so that you avoid measurement error coming from finite timer accuracy. We distinguish between precision and accuracy here: just because the system may provide a timer with nanosecond precision does not automatically guarantee that it has nanosecond \textit{accuracy}. In principle we can calibrate the timer for a given system to measure its accuracy. In practice, we simply assume a given accuracy, say 1 microsecond, and proceed accordingly.

A common rule of thumb used in practice is to repeat the benchmark enough times, say $n$, so that the total execution time exceeds a certain minimum period, say 5--20 seconds. The relative accuracy of assessing the actual run time is increased. A useful analogy is how you can get a more precise measurement of the weight of a single sheet of paper if you weigh 500 sheets on scale and divide the measurement by 500, as opposed to weighing just a single sheet directly.

Nominally it looks like the relative accuracy of this process should be 1 μs/10s = $10^{-7}$. However, the longer you run the program the more OS jitter you will pick up in the timing. Different benchmarks pick up different jitter. For example memory heavy benchmarks may pick up more cache misses while I/O heavy benchmarks may pick up more hard disk latency. So in practice you want to run the benchmark long enough to minimize timer accuracy error while not pick up too much jitter, and a hard rule of thumb like 5--20 seconds may be too much or not enough.

Some papers
\TODO{who?}
advocate a linear search methodology to choose the optimal $n$ where you keep increasing the number of repetitions linearly up to a fixed upper bound, say 1 minute, then do a linear regression to find which region starts to exhibit linear scaling with the number of repetitions. However, a common error in these descriptions is that they tend to also include many data points with total times comparable or less than the timer accuracy. Actually we should throw all of these away because having many inaccurate points biases the least squares search. Or maybe we should do instead weighted least squares so that the regression knows something about error bars. In practice throwing away the short runs suffices. Also you don't want to have too many data points with very long run times because you may start to trigger new jitter factors with longer characteristic time scales.

Let's justify the linear search strategy. Let $h$ be timer resolution noise, $n_1, n_2, ..., n_k$ be a sequence for the number of repetitions $n$ to be tried, and $T_j$ be the execution time measured when the number of repetitions is $n_j$. We assume that the measured execution time can be decomposed into

\begin{equation}
    T_j = n_j \tau + h + jitter
\end{equation}
%
where $\tau$ is the true execution time for the benchmark. If the $h + jitter$ term is constant then a linear regression will have slope $\tau$ and intercept $h + jitter$. In practice the jitter term will also grow with $n_j$ and this complicates the analysis.

We therefore recommend a truncated linear regression trimming all runs lasting less than the timer accuracy of 1 μs.

\label{sec:statmodel}
\subsection{A simple statistical model for nondeterministic execution times in the presence of OS jitter}

In this work we adopt a simple model for program execution. Assume for the moment that we have only a single instruction pipeline and that the user's program $P_0$ may be specified as a single sequence of instructions, which we shall denote

$P_0$ = \begin{tabular}{|c|c|c|c|c|}
\hline
$I_1$ & $I_2$ & $\cdots$ & $I_N$ \tabularnewline
\hline
\end{tabular}

Assume that each instruction $I_i$ takes exactly one clock cycle. In an idealized universe, the user program $P_0$ will execute in time $T_0 = N$ clock cycles. However, due to any of the external factors mentioned above, the CPU or operating system may choose to do things other than one of the instructions $I_k$. We model this by saying that the idealized program $P_0$ is transformed into a new program $P$, which consists of the same sequence of instructions  from the user's program $P_0$, but interleaved with delay instructions $D_j$:

$P$ = \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline
$D_1$ & $I_1$ & $D_2$ & $I_2$ &
$\cdots$ & $D_N$ & $I_N$ & $D_{N+1}$
\tabularnewline
\hline
\end{tabular}

The delay instructions model branching to instructions that do not belong to $P_0$, but are nevertheless run because they are triggered by the environment of $P_0$, such as its operating system or hardware state, or even a network interrupt. The run time of $P$ is no longer $N$, but
$T_P = N + \sum_{j=1}^{N+1} D_j$.

Further imagine that this machine has $N_f$ independent factors of OS (environmental) jitter, which we label in superscripts $\cdot^{(i)}$. Each jitter factor can trigger with probability $p^{(i)}$, and each time the jitter factor is triggered, it will take time $T^{(i)}$ to run. Let $x^{i}_j \in \{0, 1\}$ indicate whether the $i$th jitter factor is triggered each time in the random delay instruction $R_j$. Then the run time of $D_j$ is
$T_{D_j} = \sum_{i=1}^{N_f} x^{(i)}_j T^{(i)}$ and is no longer deterministic, but instead a random variable.

Putting all these things together, we get

\begin{equation}
T_P = N + \sum_{j=1}^{N+1} \sum_{i=1}^{N_f} x^{(i)}_j T^{(i)}
= N + \sum_{i=1}^{N_f} X_P^{(i)} T^{(i)},
\end{equation}
%
where $X_P^{(i)} = \sum_{j=1}^{N+1} x^{(i)}_j$ is the number of times the jitter factor $i$ was triggered when running the program $P$.

The randomness has a natural interpretation in the Kolmogorov formulation of probability. We could in principle gather so much information about the exact microscopic configuration $\mathcal S$ of a computer, down to its precise hardware specification, operating temperature, and all the bits in its I/O streams, caches, buffers, and storage devices, and so on, that we could know deterministically how long each delay instruction $D_j$ would take to run. If we could also restore the computer to the precise state $\mathcal S$ after running the program $P$, then the computer will execute $P$ again with exactly the same, deterministic run time. In practice, however, we never know $\mathcal S$ with enough detail to describe $T_P$ deterministically. Instead, we must make do with an imprecise specification of the machine state, saying instead that the machine state $\mathcal S$ is only known to belong to some set $S$ of possible machine states belonging to the sample space $\Omega$. In this sense, our probabilistic description of program execution is reminiscent of the microcanonical ensemble in statistical mechanics.

Let's note a few properties of this model:

First of all, $T_P \ge T_0$ since each characteristic time $T^{(i)} > 0$ is positive. Therefore $P$ always takes more time to execute than $P_0$. More importantly, there must exist some critical time $T^*_P$ for which the probability density function (pdf) $f_P(t)$ of $T_P$ of obeys $f_P(t) = 0 \; \forall \; t < T^*_P$. The critical time $T^*_P \ge T_0$, with equality holding if and only if there exists some microscopic configuration $\mathcal S$ such that no factors of OS jitter are triggered, i.e.\ $x^{(i)}_j = 0$ for all factors $i$ and instructions $j$.

Secondly, there are special case limiting behaviors that make a lot of sense. For example, if there is only $N_f = 1$ factor of OS jitter, then $X^{(1)}$ follows a binomial distribution with $N$ samples and proability $p^{(1)}$. If furthermore the number of instructions $N$ is sufficiently large, then and there is only $N_f = 1$ factor of OS jitter, then the behavior of $X^{(1)}$ follows a Poisson (exponential) distribution with rate $p^{(1)} N$. If there are $N_f > 1$ factors of OS jitter, each with identical trigger probability $p^{(i)} = \pi$ and characteristic time scale $T^(i) = \tau$, then $X = \sum_{i=1}^{N_f} X^{(i)}$ follows an Erlang distribution with shape parameter $k$ and rate $p^{(1)} N$. Of course in practice, few benchmarks obey such idealized behavior, but they are useful limiting cases to bear in mind. Furthermore our model is general enough to cover the wide variety of distributions seen in practice. An important nonideal case is the observation of two or more modes in $f_P$. Such behavior is consistent with a model $T_P = T_Y Y + T_Z Z$, where $T_Y$ and $T_Z \ne T_Y$ are constants describing a characteristic time scales associated with random variables $Y$ and $Z$ respectively, and $Y$ is an Erlang distribution and $Z$ is a binomial distribution.


\subsection{A hypothesis testing approach to regression testing}

We are now ready to make use of all this probablisitic machinery to describe the statistics of regression benchmarking. Suppose we have a reference program $P$ and a modified program $Q$ which produce the same output when given identical inputs. We now want to know if $P$ is slower than $Q$. Again in a perfectly deterministic universe where there are no OS jitter factors or the starting machine state $\mathcal S$ known with great precision and can be reproduced on demand, then we simply run $P$, time how long it takes, reset the machine back to its starting state $\mathcal S$, and then run $Q$, noting how long it takes to run. However $\mathcal S$ is never known exactly, and even if it were known, it's not clear if
$\mathcal S$ represents a ``typical'' machine configuration encountered in practice.

We are thus inexorably led to consider instead the statistical question of whether

\begin{equation}
\Delta T = T_Q - T_P
= (T^*_P - T^*_Q) + \sum_{i=1}^{N_f} (X^{(i)}_P - X^{(i)}_Q) T^{(i)}
\end{equation}
%
is statistically positive.

What we need to do now is to distinguish the constant factor $T^*_P - T^*_Q$, the part we care about, from the second term, representing differences in OS jitter triggers.

\TODO{... SKIP SOME STEPS ...}

Let $l_P$ and $l_Q$ be location parameters, such as the means, medians, minima, or interquartile ranges that characterize $f_P$ and $f_Q$. Then we can write down a hypothesis test

\begin{subequations}
\begin{align}
H_0&: l_P = l_Q \\
H_1&: l_P < l_Q
\end{align}
\end{subequations}

If $H_1$ is true, then we have a performance regression if program $Q$ replaces program $P$.

There is a question of what location parameter to use.
One may want to use the means, but as we all know the means are sensitive to large outliers. We see large outliers in the benchmark data, which happens when some OS jitter factor with a very long delay is triggered. Quantile-based measures such as the mean and minimum are sensitive to non-stationary OS jitter, for example if there is some jitter factor $i$ such that $X^{(i)}_P = 1$ while $X^{(i)}_Q = 0$ determistically. There is a fundamental definition problem in this situation. If we acknowledge that factor $i$ is always triggered once every time program $P$ runs but not in $Q$, then we could could fold the contribution of factor $i$ into the definition of $T^*_P$, recognizing that it is not possible to run $P$ without triggering factor $i$. However, it is impossible to distinguish statistically between this case and non-stationary jitter, i.e.\ jitter that changes the machine's behavior for a time period longer than, say, the combined run times of $P$ and $Q$. For example, the OS may decide to start paging virtual memory to disk halfway through running $P$, which continues all throughout the time when the user runs $Q$. Another possibility is that the machine running the benchmark encounters an unusally high level of network traffic when running $P$ and $Q$, for example if the machine is suffering a DDoS attack. The only way to detect this kind of nonstationary noise is to run $P$ and $Q$ enough times so that the combined run time exceeds the characteristic time scale for this jitter. However, in practice this may require benchmarks to run for unacceptably long times.

Therefore our current recommendation is to use an inter-quantile range as the location parameter. It is easy to calculate the estimators $\hat l_P$ and $\hat l_Q$. However, we don't know analytically what the distribution of $l_P - l_Q$ looks like, which we need to know in order to describe the appropriate time scale $\tau$ to describe statistical significance. (This time scale generalizes the standard error of the $t$-statistic when comparing the means of two Gaussians.) So we use a bootstrap procedure to estimate this scale $\tau$~\cite{Efron1981}.

\subsection{A bootstrap procedure for hypothesis testing}

The thing we don't know h

\TODO{jiahao to fill in}

\begin{figure}[!t]
\centering
\TODOFIG{Ideal benchmark timings}
%\includegraphics[width=2.5in]{myfigure}
\caption{How benchmark timings ought to scale with the number of repetitions $n$ according to the statistical model of Sec.~\ref{sec:statmodel}.}
\label{fig:idealscaling}
\end{figure}

\section{Results on some Julia benchmarks}

\begin{figure}[!t]
\centering
\TODOFIG{Some clusters}
%\includegraphics[width=2.5in]{myfigure}
\caption{Clustering of Julia benchmarks.}
\label{fig:benchclusters}
\end{figure}

\begin{figure}[!t]
\centering
\TODOFIG{Real benchmark timings}
%\includegraphics[width=2.5in]{myfigure}
\caption{How benchmark timings scale with the number of repetitions $n$.}
\label{fig:scaling}
\end{figure}

% An example of a floating table. Note that, for IEEE style tables, the
% \caption command should come BEFORE the table and, given that table
% captions serve much like titles, are usually capitalized except for words
% such as a, an, and, as, at, but, by, for, in, nor, of, on, or, the, to
% and up, which are usually not capitalized unless they are the first or
% last word of the caption. Table text will default to \footnotesize as
% the IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}

\section{Conclusion}

\TODO{The conclusion goes here.}

\section*{Acknowledgment}

We thank the many Julia developers for many insightful discussions.

This work was supported by the Nanosoldier grant.\TODO{Get grant info}

\bibliography{biblio}
\bibliographystyle{IEEEtran}

% that's all folks
\end{document}
